{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO data preprocessing\n",
    "\n",
    "This code will download the caption anotations for coco and preprocess them into an hdf5 file and a json file. \n",
    "\n",
    "These will then be read by the COCO data loader in Lua and trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'images', u'annotations']\n",
      "40504 82783\n",
      "121512 248349\n",
      "{u'license': 3, u'file_name': u'COCO_val2014_000000391895.jpg', u'coco_url': u'http://mscoco.org/images/391895', u'height': 360, u'width': 640, u'date_captured': u'2013-11-14 11:18:45', u'flickr_url': u'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', u'id': 391895}\n",
      "{u'image_id': 350623, u'id': 350623, u'caption': u'What is the table made of?'}\n",
      "[{'captions': u'Is the road paved?', 'file_path': u'val2014/COCO_val2014_000000391895.jpg', 'id': 391895}, {'captions': u'Is the lady holding the knife right?', 'file_path': u'val2014/COCO_val2014_000000522418.jpg', 'id': 522418}, {'captions': u'What animal is this?', 'file_path': u'val2014/COCO_val2014_000000184613.jpg', 'id': 184613}, {'captions': u'What brand is the keyboard?', 'file_path': u'val2014/COCO_val2014_000000318219.jpg', 'id': 318219}, {'captions': u'Does every person in the photo appear to be wearing headphones?', 'file_path': u'val2014/COCO_val2014_000000554625.jpg', 'id': 554625}, {'captions': u'Is the rolling pin being used?', 'file_path': u'val2014/COCO_val2014_000000397133.jpg', 'id': 397133}, {'captions': u'What color is the ladys dress?', 'file_path': u'val2014/COCO_val2014_000000574769.jpg', 'id': 574769}, {'captions': u\"Is that a watch on someone's hand?\", 'file_path': u'val2014/COCO_val2014_000000060623.jpg', 'id': 60623}, {'captions': u'Is the pot on the burner almost empty?', 'file_path': u'val2014/COCO_val2014_000000309022.jpg', 'id': 309022}, {'captions': u'Are the men about the same age?', 'file_path': u'val2014/COCO_val2014_000000005802.jpg', 'id': 5802}]\n"
     ]
    }
   ],
   "source": [
    "# lets download the annotations from http://mscoco.org/dataset/#download\n",
    "import os\n",
    "#os.system('wget http://msvocds.blob.core.windows.net/annotations-1-0-3/captions_train-val2014.zip') # ~19MB\n",
    "\n",
    "#os.system('unzip captions_train-val2014.zip')\n",
    "\n",
    "import json\n",
    "val = json.load(open('val_vqa.json', 'r'))\n",
    "train = json.load(open('train_vqa.json', 'r'))\n",
    "\n",
    "print val.keys()\n",
    "#print val['info']\n",
    "print len(val['images']), len(train['images'])\n",
    "print len(val['annotations']), len(train['annotations'])\n",
    "print val['images'][0]\n",
    "print val['annotations'][0]\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# combine all images and annotations together\n",
    "imgs = val['images'] + train['images']\n",
    "annots = val['annotations'] + train['annotations']\n",
    "\n",
    "# for efficiency lets group annotations by image\n",
    "itoa = {}\n",
    "for a in annots:\n",
    "    imgid = a['image_id']\n",
    "    if not imgid in itoa: itoa[imgid] = []\n",
    "    itoa[imgid].append(a)\n",
    "\n",
    "# create the json blob\n",
    "out = []\n",
    "for i,img in enumerate(imgs):\n",
    "    imgid = img['id']\n",
    "    \n",
    "    # coco specific here, they store train/val images separately\n",
    "    loc = 'train2014' if 'train' in img['file_name'] else 'val2014'\n",
    "    \n",
    "    jimg = {}\n",
    "    jimg['file_path'] = os.path.join(loc, img['file_name'])\n",
    "    jimg['id'] = imgid\n",
    "    \n",
    "    sents = []\n",
    "    annotsi = itoa[imgid]\n",
    "    for a in annotsi:\n",
    "        sents.append(a['caption'])\n",
    "    jimg['captions'] = sents[0]\n",
    "    out.append(jimg)\n",
    "    \n",
    "json.dump(out, open('coco_raw_vqa.json', 'w'))\n",
    "\n",
    "# lets see what they look like\n",
    "print out[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open('coco_raw_vqa.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'captions': u'What brand is the keyboard?',\n",
       " u'file_path': u'val2014/COCO_val2014_000000318219.jpg',\n",
       " u'id': 318219}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
